{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\n",
    "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (1306122, 3)\n",
      "Test shape :  (375806, 2)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"./data/train.csv\")\n",
    "test_df = pd.read_csv(\"./data/test.csv\")\n",
    "print(\"Train shape : \", train_df.shape)\n",
    "print(\"Test shape : \", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 375806 entries, 0 to 375805\n",
      "Data columns (total 2 columns):\n",
      "qid              375806 non-null object\n",
      "question_text    375806 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 5.7+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1306122 entries, 0 to 1306121\n",
      "Data columns (total 3 columns):\n",
      "qid              1306122 non-null object\n",
      "question_text    1306122 non-null object\n",
      "target           1306122 non-null int64\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 29.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame.info(test_df))\n",
    "print(pd.DataFrame.info(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 50000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 100 # max number of words in a question to use\n",
    "\n",
    "## fill up the missing values\n",
    "train_X = train_df[\"question_text\"].values\n",
    "val_X = val_df[\"question_text\"].values\n",
    "test_X = test_df[\"question_text\"].values\n",
    "\n",
    "## Tokenize the sentences\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(train_X))\n",
    "train_X = tokenizer.texts_to_sequences(train_X)\n",
    "val_X = tokenizer.texts_to_sequences(val_X)\n",
    "test_X = tokenizer.texts_to_sequences(test_X)\n",
    "\n",
    "## Pad the sentences \n",
    "train_X = pad_sequences(train_X, maxlen=maxlen)\n",
    "val_X = pad_sequences(val_X, maxlen=maxlen)\n",
    "test_X = pad_sequences(test_X, maxlen=maxlen)\n",
    "\n",
    "## Get the target values\n",
    "train_y = train_df['target'].values\n",
    "val_y = val_df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mmh/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/mmh/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/mmh/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/mmh/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/mmh/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/mmh/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 100, 300)          15000000  \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 100, 128)          140544    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 15,142,625\n",
      "Trainable params: 15,142,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(maxlen,))\n",
    "x = Embedding(max_features, embed_size)(inp)\n",
    "x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(16, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1175509 samples, validate on 130613 samples\n",
      "Epoch 1/2\n",
      "1175509/1175509 [==============================] - 256s 218us/sample - loss: 0.1224 - acc: 0.9533 - val_loss: 0.1073 - val_acc: 0.9581\n",
      "Epoch 2/2\n",
      "1175509/1175509 [==============================] - 247s 210us/sample - loss: 0.0977 - acc: 0.9610 - val_loss: 0.1058 - val_acc: 0.9587\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f63fbcaae80>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_y, batch_size=512, epochs=2, validation_data=(val_X, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130613/130613 [==============================] - 7s 50us/sample\n",
      "F1 score at threshold 0.1 is 0.5784884957257687\n",
      "F1 score at threshold 0.11 is 0.5863810518982933\n",
      "F1 score at threshold 0.12 is 0.5949192507896961\n",
      "F1 score at threshold 0.13 is 0.6006983810258039\n",
      "F1 score at threshold 0.14 is 0.6072934525740235\n",
      "F1 score at threshold 0.15 is 0.611993028404541\n",
      "F1 score at threshold 0.16 is 0.6165132336018412\n",
      "F1 score at threshold 0.17 is 0.6212504869497467\n",
      "F1 score at threshold 0.18 is 0.6255807057428091\n",
      "F1 score at threshold 0.19 is 0.6304914744232699\n",
      "F1 score at threshold 0.2 is 0.6342382722966433\n",
      "F1 score at threshold 0.21 is 0.6366310574392321\n",
      "F1 score at threshold 0.22 is 0.6385158087274627\n",
      "F1 score at threshold 0.23 is 0.6405422579961872\n",
      "F1 score at threshold 0.24 is 0.6418639609169485\n",
      "F1 score at threshold 0.25 is 0.6437605167453727\n",
      "F1 score at threshold 0.26 is 0.6444517760914991\n",
      "F1 score at threshold 0.27 is 0.6446666666666666\n",
      "F1 score at threshold 0.28 is 0.645878981965279\n",
      "F1 score at threshold 0.29 is 0.6474257201179405\n",
      "F1 score at threshold 0.3 is 0.6489526542324247\n",
      "F1 score at threshold 0.31 is 0.6491594202898551\n",
      "F1 score at threshold 0.32 is 0.6498097746561311\n",
      "F1 score at threshold 0.33 is 0.6510416666666666\n",
      "F1 score at threshold 0.34 is 0.6512713131917439\n",
      "F1 score at threshold 0.35 is 0.6498099088769537\n",
      "F1 score at threshold 0.36 is 0.6491559510024986\n",
      "F1 score at threshold 0.37 is 0.647587395371738\n",
      "F1 score at threshold 0.38 is 0.6465148035503693\n",
      "F1 score at threshold 0.39 is 0.6457798107650856\n",
      "F1 score at threshold 0.4 is 0.6443826614431949\n",
      "F1 score at threshold 0.41 is 0.6432346386501114\n",
      "F1 score at threshold 0.42 is 0.6433799922948503\n",
      "F1 score at threshold 0.43 is 0.6422315926046058\n",
      "F1 score at threshold 0.44 is 0.6424511661331418\n",
      "F1 score at threshold 0.45 is 0.6411388650893033\n",
      "F1 score at threshold 0.46 is 0.6389665734451991\n",
      "F1 score at threshold 0.47 is 0.6377142857142857\n",
      "F1 score at threshold 0.48 is 0.6341562669560499\n",
      "F1 score at threshold 0.49 is 0.6308366424756949\n",
      "F1 score at threshold 0.5 is 0.6273506637168141\n"
     ]
    }
   ],
   "source": [
    "pred_noemb_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_noemb_val_y>thresh).astype(int))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375806/375806 [==============================] - 19s 50us/sample\n"
     ]
    }
   ],
   "source": [
    "pred_noemb_test_y = model.predict([test_X], batch_size=1024, verbose=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model, inp, x\n",
    "import gc; gc.collect()\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove.840B.300d\t\t\tsample_submission.csv  wiki-news-300d-1M\r\n",
      "GoogleNews-vectors-negative300\ttest.csv\r\n",
      "paragram_300_sl999\t\ttrain.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 100, 300)          15000000  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 100, 128)          140544    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 15,142,625\n",
      "Trainable params: 15,142,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_FILE = './data/glove.840B.300d/glove.840B.300d.txt'\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
    "\n",
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "inp = Input(shape=(maxlen,))\n",
    "x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(16, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1175509 samples, validate on 130613 samples\n",
      "Epoch 1/2\n",
      "1175509/1175509 [==============================] - 248s 211us/sample - loss: 0.1198 - acc: 0.9550 - val_loss: 0.1016 - val_acc: 0.9605\n",
      "Epoch 2/2\n",
      "1175509/1175509 [==============================] - 250s 213us/sample - loss: 0.0949 - acc: 0.9627 - val_loss: 0.0999 - val_acc: 0.9604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f636842f278>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_y, batch_size=512, epochs=2, validation_data=(val_X, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130613/130613 [==============================] - 7s 50us/sample\n",
      "F1 score at threshold 0.1 is 0.5982450103234687\n",
      "F1 score at threshold 0.11 is 0.6058021978021978\n",
      "F1 score at threshold 0.12 is 0.6122869955156951\n",
      "F1 score at threshold 0.13 is 0.6190606725146198\n",
      "F1 score at threshold 0.14 is 0.6244133636912784\n",
      "F1 score at threshold 0.15 is 0.6288654926585147\n",
      "F1 score at threshold 0.16 is 0.633236040001914\n",
      "F1 score at threshold 0.17 is 0.6362710384634039\n",
      "F1 score at threshold 0.18 is 0.6395914158031724\n",
      "F1 score at threshold 0.19 is 0.64464454504751\n",
      "F1 score at threshold 0.2 is 0.6480931029270997\n",
      "F1 score at threshold 0.21 is 0.6511556867936056\n",
      "F1 score at threshold 0.22 is 0.6542219479584491\n",
      "F1 score at threshold 0.23 is 0.6572691807542262\n",
      "F1 score at threshold 0.24 is 0.6594145777497503\n",
      "F1 score at threshold 0.25 is 0.6611807177744744\n",
      "F1 score at threshold 0.26 is 0.6623077335334155\n",
      "F1 score at threshold 0.27 is 0.6636756756756756\n",
      "F1 score at threshold 0.28 is 0.6651376146788991\n",
      "F1 score at threshold 0.29 is 0.6668504935752495\n",
      "F1 score at threshold 0.3 is 0.668038713983758\n",
      "F1 score at threshold 0.31 is 0.6684986820705513\n",
      "F1 score at threshold 0.32 is 0.6696458875438398\n",
      "F1 score at threshold 0.33 is 0.6706224681919325\n",
      "F1 score at threshold 0.34 is 0.6711525189786058\n",
      "F1 score at threshold 0.35 is 0.671463386329349\n",
      "F1 score at threshold 0.36 is 0.6725477595373022\n",
      "F1 score at threshold 0.37 is 0.6731822196055343\n",
      "F1 score at threshold 0.38 is 0.6740639648727229\n",
      "F1 score at threshold 0.39 is 0.6732815301852959\n",
      "F1 score at threshold 0.4 is 0.6729343699150244\n",
      "F1 score at threshold 0.41 is 0.6723729739573848\n",
      "F1 score at threshold 0.42 is 0.6715988994191379\n",
      "F1 score at threshold 0.43 is 0.6705679438216089\n",
      "F1 score at threshold 0.44 is 0.6703092015397989\n",
      "F1 score at threshold 0.45 is 0.6690886313811464\n",
      "F1 score at threshold 0.46 is 0.668267104681281\n",
      "F1 score at threshold 0.47 is 0.6659445683338643\n",
      "F1 score at threshold 0.48 is 0.6644821382677976\n",
      "F1 score at threshold 0.49 is 0.6633817427385893\n",
      "F1 score at threshold 0.5 is 0.6613472858077174\n"
     ]
    }
   ],
   "source": [
    "pred_glove_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_glove_val_y>thresh).astype(int))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375806/375806 [==============================] - 19s 50us/sample\n"
     ]
    }
   ],
   "source": [
    "pred_glove_test_y = model.predict([test_X], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del word_index, embeddings_index, all_embs, embedding_matrix, model, inp, x\n",
    "import gc; gc.collect()\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_FILE = './data/wiki-news-300d-1M/wiki-news-300d-1M.vec'\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE) if len(o)>100)\n",
    "\n",
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "inp = Input(shape=(maxlen,))\n",
    "x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(16, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1175509 samples, validate on 130613 samples\n",
      "Epoch 1/2\n",
      "1175509/1175509 [==============================] - 253s 215us/sample - loss: 0.0807 - acc: 0.9680 - val_loss: 0.1098 - val_acc: 0.9593\n",
      "Epoch 2/2\n",
      "1175509/1175509 [==============================] - 251s 214us/sample - loss: 0.0639 - acc: 0.9747 - val_loss: 0.1268 - val_acc: 0.9551\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f62d1401390>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_y, batch_size=512, epochs=2, validation_data=(val_X, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130613/130613 [==============================] - 7s 52us/sample\n",
      "F1 score at threshold 0.1 is 0.5801220575414124\n",
      "F1 score at threshold 0.11 is 0.5863948592953689\n",
      "F1 score at threshold 0.12 is 0.5924925735889819\n",
      "F1 score at threshold 0.13 is 0.5969576538303413\n",
      "F1 score at threshold 0.14 is 0.6010458605210792\n",
      "F1 score at threshold 0.15 is 0.6039325842696629\n",
      "F1 score at threshold 0.16 is 0.6073273614863264\n",
      "F1 score at threshold 0.17 is 0.6104779235705392\n",
      "F1 score at threshold 0.18 is 0.6134185303514377\n",
      "F1 score at threshold 0.19 is 0.6155800996969993\n",
      "F1 score at threshold 0.2 is 0.6185658589547451\n",
      "F1 score at threshold 0.21 is 0.6194531600179292\n",
      "F1 score at threshold 0.22 is 0.6216596343178622\n",
      "F1 score at threshold 0.23 is 0.6228860759493671\n",
      "F1 score at threshold 0.24 is 0.6239207070965105\n",
      "F1 score at threshold 0.25 is 0.62617304320924\n",
      "F1 score at threshold 0.26 is 0.6269432745801488\n",
      "F1 score at threshold 0.27 is 0.629808702964053\n",
      "F1 score at threshold 0.28 is 0.6294706723891274\n",
      "F1 score at threshold 0.29 is 0.6300608909304563\n",
      "F1 score at threshold 0.3 is 0.6309433962264152\n",
      "F1 score at threshold 0.31 is 0.6318424202851235\n",
      "F1 score at threshold 0.32 is 0.6326474622770919\n",
      "F1 score at threshold 0.33 is 0.6326214451698573\n",
      "F1 score at threshold 0.34 is 0.6333407721490739\n",
      "F1 score at threshold 0.35 is 0.6354172528276405\n",
      "F1 score at threshold 0.36 is 0.6361057528650856\n",
      "F1 score at threshold 0.37 is 0.6355685131195336\n",
      "F1 score at threshold 0.38 is 0.6356410551779749\n",
      "F1 score at threshold 0.39 is 0.6361893697356956\n",
      "F1 score at threshold 0.4 is 0.6364540085375124\n",
      "F1 score at threshold 0.41 is 0.6361761065597926\n",
      "F1 score at threshold 0.42 is 0.6353318676094836\n",
      "F1 score at threshold 0.43 is 0.634861726325871\n",
      "F1 score at threshold 0.44 is 0.6352019288728149\n",
      "F1 score at threshold 0.45 is 0.6328913757450432\n",
      "F1 score at threshold 0.46 is 0.6333190473274963\n",
      "F1 score at threshold 0.47 is 0.6326442456032089\n",
      "F1 score at threshold 0.48 is 0.631513415924796\n",
      "F1 score at threshold 0.49 is 0.6312492168901142\n",
      "F1 score at threshold 0.5 is 0.6295570859922917\n"
     ]
    }
   ],
   "source": [
    "pred_fasttext_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_fasttext_val_y>thresh).astype(int))))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375806/375806 [==============================] - 19s 50us/sample\n"
     ]
    }
   ],
   "source": [
    "pred_fasttext_test_y = model.predict([test_X], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "del word_index, embeddings_index, all_embs, embedding_matrix, model, inp, x\n",
    "import gc; gc.collect()\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_FILE = './data/paragram_300_sl999/paragram_300_sl999.txt'\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE, encoding=\"utf8\", errors='ignore') if len(o)>100)\n",
    "\n",
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "inp = Input(shape=(maxlen,))\n",
    "x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(16, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1175509 samples, validate on 130613 samples\n",
      "Epoch 1/2\n",
      "1175509/1175509 [==============================] - 249s 212us/sample - loss: 0.1176 - acc: 0.9548 - val_loss: 0.1023 - val_acc: 0.9603\n",
      "Epoch 2/2\n",
      "1175509/1175509 [==============================] - 247s 211us/sample - loss: 0.0963 - acc: 0.9622 - val_loss: 0.1016 - val_acc: 0.9606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f62aeab1b70>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_y, batch_size=512, epochs=2, validation_data=(val_X, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130613/130613 [==============================] - 7s 52us/sample\n",
      "F1 score at threshold 0.1 is 0.6101603314718069\n",
      "F1 score at threshold 0.11 is 0.6189838955285867\n",
      "F1 score at threshold 0.12 is 0.6257888292361308\n",
      "F1 score at threshold 0.13 is 0.6310949324647955\n",
      "F1 score at threshold 0.14 is 0.6368028107158542\n",
      "F1 score at threshold 0.15 is 0.6426689205986179\n",
      "F1 score at threshold 0.16 is 0.646829613885937\n",
      "F1 score at threshold 0.17 is 0.6516218578111345\n",
      "F1 score at threshold 0.18 is 0.6550268410903215\n",
      "F1 score at threshold 0.19 is 0.6576457529467731\n",
      "F1 score at threshold 0.2 is 0.6604481612522782\n",
      "F1 score at threshold 0.21 is 0.662868923611111\n",
      "F1 score at threshold 0.22 is 0.6647998682259924\n",
      "F1 score at threshold 0.23 is 0.6664443703456707\n",
      "F1 score at threshold 0.24 is 0.6685033172157877\n",
      "F1 score at threshold 0.25 is 0.6708795900939367\n",
      "F1 score at threshold 0.26 is 0.6713045478065889\n",
      "F1 score at threshold 0.27 is 0.6720873504472065\n",
      "F1 score at threshold 0.28 is 0.6722955145118734\n",
      "F1 score at threshold 0.29 is 0.6719895907262834\n",
      "F1 score at threshold 0.3 is 0.672635034318114\n",
      "F1 score at threshold 0.31 is 0.6723306820920704\n",
      "F1 score at threshold 0.32 is 0.6720913286373573\n",
      "F1 score at threshold 0.33 is 0.6711598554010171\n",
      "F1 score at threshold 0.34 is 0.669633475492923\n",
      "F1 score at threshold 0.35 is 0.6689104961356271\n",
      "F1 score at threshold 0.36 is 0.6666247958799146\n",
      "F1 score at threshold 0.37 is 0.6661184210526315\n",
      "F1 score at threshold 0.38 is 0.6650092433224962\n",
      "F1 score at threshold 0.39 is 0.6637969804047543\n",
      "F1 score at threshold 0.4 is 0.6624352331606218\n",
      "F1 score at threshold 0.41 is 0.662178062491829\n",
      "F1 score at threshold 0.42 is 0.660036880927292\n",
      "F1 score at threshold 0.43 is 0.6564327485380117\n",
      "F1 score at threshold 0.44 is 0.6558145766345124\n",
      "F1 score at threshold 0.45 is 0.6518978792381467\n",
      "F1 score at threshold 0.46 is 0.6491419231816944\n",
      "F1 score at threshold 0.47 is 0.64629960181244\n",
      "F1 score at threshold 0.48 is 0.6442860109365266\n",
      "F1 score at threshold 0.49 is 0.6408052002516251\n",
      "F1 score at threshold 0.5 is 0.6364536199095022\n"
     ]
    }
   ],
   "source": [
    "pred_paragram_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_paragram_val_y>thresh).astype(int))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375806/375806 [==============================] - 19s 50us/sample\n"
     ]
    }
   ],
   "source": [
    "pred_paragram_test_y = model.predict([test_X], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "del word_index, embeddings_index, all_embs, embedding_matrix, model, inp, x\n",
    "import gc; gc.collect()\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score at threshold 0.1 is 0.5955171528787749\n",
      "F1 score at threshold 0.11 is 0.6028532786527638\n",
      "F1 score at threshold 0.12 is 0.6095119455443342\n",
      "F1 score at threshold 0.13 is 0.6152523195293053\n",
      "F1 score at threshold 0.14 is 0.6210985980234429\n",
      "F1 score at threshold 0.15 is 0.6263408264154463\n",
      "F1 score at threshold 0.16 is 0.6321773735076748\n",
      "F1 score at threshold 0.17 is 0.6362719192889743\n",
      "F1 score at threshold 0.18 is 0.6400740307812195\n",
      "F1 score at threshold 0.19 is 0.6434920007900454\n",
      "F1 score at threshold 0.2 is 0.6476180944755805\n",
      "F1 score at threshold 0.21 is 0.6507060788581264\n",
      "F1 score at threshold 0.22 is 0.653393387245368\n",
      "F1 score at threshold 0.23 is 0.6562435286808863\n",
      "F1 score at threshold 0.24 is 0.6592635273165365\n",
      "F1 score at threshold 0.25 is 0.6614806583055513\n",
      "F1 score at threshold 0.26 is 0.6643117105544851\n",
      "F1 score at threshold 0.27 is 0.6666666666666667\n",
      "F1 score at threshold 0.28 is 0.6684164479440069\n",
      "F1 score at threshold 0.29 is 0.6697242636901144\n",
      "F1 score at threshold 0.3 is 0.6691603394372488\n",
      "F1 score at threshold 0.31 is 0.6712615106491159\n",
      "F1 score at threshold 0.32 is 0.6727573802318279\n",
      "F1 score at threshold 0.33 is 0.6729371032890941\n",
      "F1 score at threshold 0.34 is 0.6731082654249128\n",
      "F1 score at threshold 0.35 is 0.673323152825091\n",
      "F1 score at threshold 0.36 is 0.6744144678327898\n",
      "F1 score at threshold 0.37 is 0.6748818567924867\n",
      "F1 score at threshold 0.38 is 0.6742781200918208\n",
      "F1 score at threshold 0.39 is 0.6744639376218323\n",
      "F1 score at threshold 0.4 is 0.6745044934137633\n",
      "F1 score at threshold 0.41 is 0.6729993170671136\n",
      "F1 score at threshold 0.42 is 0.6721023582538885\n",
      "F1 score at threshold 0.43 is 0.6714792299898682\n",
      "F1 score at threshold 0.44 is 0.6696901948259342\n",
      "F1 score at threshold 0.45 is 0.6676125370824196\n",
      "F1 score at threshold 0.46 is 0.6656683377824077\n",
      "F1 score at threshold 0.47 is 0.6642599277978339\n",
      "F1 score at threshold 0.48 is 0.6616292172068668\n",
      "F1 score at threshold 0.49 is 0.6592216129463688\n",
      "F1 score at threshold 0.5 is 0.6573086786340937\n"
     ]
    }
   ],
   "source": [
    "pred_val_y = 0.33*pred_glove_val_y + 0.33*pred_fasttext_val_y + 0.34*pred_paragram_val_y \n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_val_y>thresh).astype(int))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_y = 0.33*pred_glove_test_y + 0.33*pred_fasttext_test_y + 0.34*pred_paragram_test_y\n",
    "pred_test_y = (pred_test_y>0.35).astype(int)\n",
    "out_df = pd.DataFrame({\"qid\":test_df[\"qid\"].values})\n",
    "out_df['prediction'] = pred_test_y\n",
    "out_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
