{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\n",
    "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (1306122, 3)\n",
      "Test shape :  (375806, 2)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"./data/train.csv\")\n",
    "test_df = pd.read_csv(\"./data/test.csv\")\n",
    "print(\"Train shape : \",train_df.shape)\n",
    "print(\"Test shape : \",test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 375806 entries, 0 to 375805\n",
      "Data columns (total 2 columns):\n",
      "qid              375806 non-null object\n",
      "question_text    375806 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 5.7+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1306122 entries, 0 to 1306121\n",
      "Data columns (total 3 columns):\n",
      "qid              1306122 non-null object\n",
      "question_text    1306122 non-null object\n",
      "target           1306122 non-null int64\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 29.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame.info(test_df))\n",
    "print(pd.DataFrame.info(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 50000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 100 # max number of words in a question to use\n",
    "\n",
    "## fill up the missing values\n",
    "train_X = train_df[\"question_text\"].values\n",
    "val_X = val_df[\"question_text\"].values\n",
    "test_X = test_df[\"question_text\"].values\n",
    "\n",
    "## Tokenize the sentences\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(train_X))\n",
    "train_X = tokenizer.texts_to_sequences(train_X)\n",
    "val_X = tokenizer.texts_to_sequences(val_X)\n",
    "test_X = tokenizer.texts_to_sequences(test_X)\n",
    "\n",
    "## Pad the sentences \n",
    "train_X = pad_sequences(train_X, maxlen=maxlen)\n",
    "val_X = pad_sequences(val_X, maxlen=maxlen)\n",
    "test_X = pad_sequences(test_X, maxlen=maxlen)\n",
    "\n",
    "## Get the target values\n",
    "train_y = train_df['target'].values\n",
    "val_y = val_df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mmh/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/mmh/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/mmh/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/mmh/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/mmh/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/mmh/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 100, 300)          15000000  \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 100, 128)          140544    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 15,142,625\n",
      "Trainable params: 15,142,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(maxlen,))\n",
    "x = Embedding(max_features, embed_size)(inp)\n",
    "x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(16, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1175509 samples, validate on 130613 samples\n",
      "Epoch 1/2\n",
      "1175509/1175509 [==============================] - 257s 219us/sample - loss: 0.1218 - acc: 0.9534 - val_loss: 0.1058 - val_acc: 0.9581\n",
      "Epoch 2/2\n",
      "1175509/1175509 [==============================] - 251s 213us/sample - loss: 0.0970 - acc: 0.9613 - val_loss: 0.1071 - val_acc: 0.9576\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f19a096b780>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_y, batch_size=512, epochs=2, validation_data=(val_X, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130613/130613 [==============================] - 7s 53us/sample\n",
      "F1 score at threshold 0.1 is 0.5579091494845361\n",
      "F1 score at threshold 0.11 is 0.5673577269348311\n",
      "F1 score at threshold 0.12 is 0.5756694075479656\n",
      "F1 score at threshold 0.13 is 0.5837283461173834\n",
      "F1 score at threshold 0.14 is 0.5910269367667091\n",
      "F1 score at threshold 0.15 is 0.5968666069829901\n",
      "F1 score at threshold 0.16 is 0.6015112891478515\n",
      "F1 score at threshold 0.17 is 0.6071197411003237\n",
      "F1 score at threshold 0.18 is 0.6119094580633042\n",
      "F1 score at threshold 0.19 is 0.6158533682456558\n",
      "F1 score at threshold 0.2 is 0.6203038340969376\n",
      "F1 score at threshold 0.21 is 0.6238523149052551\n",
      "F1 score at threshold 0.22 is 0.6286053529906496\n",
      "F1 score at threshold 0.23 is 0.6318422896027218\n",
      "F1 score at threshold 0.24 is 0.6346475024039678\n",
      "F1 score at threshold 0.25 is 0.6372388365424007\n",
      "F1 score at threshold 0.26 is 0.6388860130448286\n",
      "F1 score at threshold 0.27 is 0.6416692814559147\n",
      "F1 score at threshold 0.28 is 0.6449053010263465\n",
      "F1 score at threshold 0.29 is 0.6458935646214797\n",
      "F1 score at threshold 0.3 is 0.6481081081081081\n",
      "F1 score at threshold 0.31 is 0.6487431693989071\n",
      "F1 score at threshold 0.32 is 0.6499421072944809\n",
      "F1 score at threshold 0.33 is 0.6503422561077411\n",
      "F1 score at threshold 0.34 is 0.6513560559267786\n",
      "F1 score at threshold 0.35 is 0.652201008441448\n",
      "F1 score at threshold 0.36 is 0.6528023767354167\n",
      "F1 score at threshold 0.37 is 0.6534048319206597\n",
      "F1 score at threshold 0.38 is 0.6537499272706114\n",
      "F1 score at threshold 0.39 is 0.6537197840882423\n",
      "F1 score at threshold 0.4 is 0.6535391165513571\n",
      "F1 score at threshold 0.41 is 0.6534972547147291\n",
      "F1 score at threshold 0.42 is 0.6530685920577617\n",
      "F1 score at threshold 0.43 is 0.6529126213592235\n",
      "F1 score at threshold 0.44 is 0.6509151006916813\n",
      "F1 score at threshold 0.45 is 0.6503392967304132\n",
      "F1 score at threshold 0.46 is 0.6495204882301657\n",
      "F1 score at threshold 0.47 is 0.6492120298863565\n",
      "F1 score at threshold 0.48 is 0.647785592092758\n",
      "F1 score at threshold 0.49 is 0.6451819170023659\n",
      "F1 score at threshold 0.5 is 0.6427465152297367\n"
     ]
    }
   ],
   "source": [
    "pred_noemb_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_noemb_val_y>thresh).astype(int))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375806/375806 [==============================] - 19s 51us/sample\n"
     ]
    }
   ],
   "source": [
    "pred_noemb_test_y = model.predict([test_X], batch_size=1024, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
