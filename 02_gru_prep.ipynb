{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import re\n",
    "from gensim import models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, CuDNNGRU, CuDNNLSTM, Conv1D\n",
    "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (1306122, 3)\n",
      "Test shape :  (375806, 2)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"./data/train.csv\")\n",
    "test_df = pd.read_csv(\"./data/test.csv\")\n",
    "print(\"Train shape : \", train_df.shape)\n",
    "print(\"Test shape : \", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 375806 entries, 0 to 375805\n",
      "Data columns (total 2 columns):\n",
      "qid              375806 non-null object\n",
      "question_text    375806 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 5.7+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1306122 entries, 0 to 1306121\n",
      "Data columns (total 3 columns):\n",
      "qid              1306122 non-null object\n",
      "question_text    1306122 non-null object\n",
      "target           1306122 non-null int64\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 29.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame.info(test_df))\n",
    "print(pd.DataFrame.info(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train_df.drop('target', axis=1) ,test_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lowered_question'] = df['question_text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_contractions(text, mapping):\n",
    "    specials = [\"’\", \"‘\", \"´\", \"`\"]\n",
    "    for s in specials:\n",
    "        text = text.replace(s, \"'\")\n",
    "    text = ' '.join([mapping[t] if t in mapping else t for t in text.split(\" \")])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['treated_question'] = df['lowered_question'].apply(lambda x: clean_contractions(x, contraction_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_mapping = {\"‘\": \"'\", \"₹\": \"e\", \"´\": \"'\", \"°\": \"\", \"€\": \"e\", \"™\": \"tm\", \"√\": \" sqrt \", \"×\": \"x\", \"²\": \"2\", \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\", \"`\": \"'\", '“': '\"', '”': '\"', '“': '\"', \"£\": \"e\", '∞': 'infinity', 'θ': 'theta', '÷': '/', 'α': 'alpha', '•': '.', 'à': 'a', '−': '-', 'β': 'beta', '∅': '', '³': '3', 'π': 'pi', }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_special_chars(text, punct, mapping):\n",
    "    for p in mapping:\n",
    "        text = text.replace(p, mapping[p])\n",
    "    \n",
    "    for p in punct:\n",
    "        text = text.replace(p, f' {p} ')\n",
    "    \n",
    "    specials = {'\\u200b': ' ', '…': ' ... ', '\\ufeff': '', 'करना': '', 'है': ''}  # Other special characters that I have to deal with in last\n",
    "    for s in specials:\n",
    "        text = text.replace(s, specials[s])\n",
    "    \n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['treated_question'] = df['treated_question'].apply(lambda x: clean_special_chars(x, punct, punct_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mispell_dict = {'colour': 'color', 'centre': 'center', 'favourite': 'favorite', 'travelling': 'traveling', 'counselling': 'counseling', 'theatre': 'theater', 'cancelled': 'canceled', 'labour': 'labor', 'organisation': 'organization', 'wwii': 'world war 2', 'citicise': 'criticize', 'youtu ': 'youtube ', 'Qoura': 'Quora', 'sallary': 'salary', 'Whta': 'What', 'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can', 'howmuch': 'how much', 'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I', 'theBest': 'the best', 'howdoes': 'how does', 'mastrubation': 'masturbation', 'mastrubate': 'masturbate', \"mastrubating\": 'masturbating', 'pennis': 'penis', 'Etherium': 'Ethereum', 'narcissit': 'narcissist', 'bigdata': 'big data', '2k17': '2017', '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend', 'airhostess': 'air hostess', \"whst\": 'what', 'watsapp': 'whatsapp', 'demonitisation': 'demonetization', 'demonitization': 'demonetization', 'demonetisation': 'demonetization'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_spelling(x, dic):\n",
    "    for word in dic.keys():\n",
    "        x = x.replace(word, dic[word])\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['treated_question'] = df['treated_question'].apply(lambda x: correct_spelling(x, mispell_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['question_text'] = df['treated_question'][:1306122]\n",
    "test_df['question_text'] = df['treated_question'][1306122:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 50000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 100 # max number of words in a question to use\n",
    "\n",
    "## fill up the missing values\n",
    "train_X = train_df[\"question_text\"].values\n",
    "val_X = val_df[\"question_text\"].values\n",
    "test_X = test_df[\"question_text\"].values\n",
    "\n",
    "## Tokenize the sentences\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(train_X))\n",
    "train_X = tokenizer.texts_to_sequences(train_X)\n",
    "val_X = tokenizer.texts_to_sequences(val_X)\n",
    "test_X = tokenizer.texts_to_sequences(test_X)\n",
    "\n",
    "## Pad the sentences \n",
    "train_X = pad_sequences(train_X, maxlen=maxlen)\n",
    "val_X = pad_sequences(val_X, maxlen=maxlen)\n",
    "test_X = pad_sequences(test_X, maxlen=maxlen)\n",
    "\n",
    "## Get the target values\n",
    "train_y = train_df['target'].values\n",
    "val_y = val_df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mmh/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/mmh/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/mmh/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/mmh/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/mmh/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/mmh/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 100, 300)          15000000  \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 100, 128)          140544    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 15,142,625\n",
      "Trainable params: 15,142,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_FILE = './data/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin'\n",
    "embeddings_index = models.KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = (np.random.rand(nb_words, embed_size) - 0.5) / 5.0\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    if word in embeddings_index:\n",
    "        embedding_vector = embeddings_index.get_vector(word)\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "inp = Input(shape=(maxlen,))\n",
    "x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(16, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1175509 samples, validate on 130613 samples\n",
      "Epoch 1/2\n",
      "1175509/1175509 [==============================] - 252s 214us/sample - loss: 0.1176 - acc: 0.9545 - val_loss: 0.1025 - val_acc: 0.9597\n",
      "Epoch 2/2\n",
      "1175509/1175509 [==============================] - 245s 209us/sample - loss: 0.0942 - acc: 0.9623 - val_loss: 0.1029 - val_acc: 0.9600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f08331387f0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_y, batch_size=512, epochs=2, validation_data=(val_X, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130613/130613 [==============================] - 7s 50us/sample\n",
      "F1 score at threshold 0.1 is 0.6034628566341746\n",
      "F1 score at threshold 0.11 is 0.6129707112970711\n",
      "F1 score at threshold 0.12 is 0.6185385718913415\n",
      "F1 score at threshold 0.13 is 0.6234120636115554\n",
      "F1 score at threshold 0.14 is 0.6295657175726201\n",
      "F1 score at threshold 0.15 is 0.6330368858434174\n",
      "F1 score at threshold 0.16 is 0.6358848141767167\n",
      "F1 score at threshold 0.17 is 0.6395928956296149\n",
      "F1 score at threshold 0.18 is 0.6431891673403396\n",
      "F1 score at threshold 0.19 is 0.6451183280401598\n",
      "F1 score at threshold 0.2 is 0.648144308521667\n",
      "F1 score at threshold 0.21 is 0.6500524658971669\n",
      "F1 score at threshold 0.22 is 0.6518534231319935\n",
      "F1 score at threshold 0.23 is 0.6536486197303659\n",
      "F1 score at threshold 0.24 is 0.6550308008213552\n",
      "F1 score at threshold 0.25 is 0.6574190377368795\n",
      "F1 score at threshold 0.26 is 0.658876701758254\n",
      "F1 score at threshold 0.27 is 0.6592135268924858\n",
      "F1 score at threshold 0.28 is 0.6596723518850988\n",
      "F1 score at threshold 0.29 is 0.6610726839777752\n",
      "F1 score at threshold 0.3 is 0.6611352712291143\n",
      "F1 score at threshold 0.31 is 0.6610472836441315\n",
      "F1 score at threshold 0.32 is 0.6625131011994876\n",
      "F1 score at threshold 0.33 is 0.6630268874016672\n",
      "F1 score at threshold 0.34 is 0.6636282923941995\n",
      "F1 score at threshold 0.35 is 0.6627657033675662\n",
      "F1 score at threshold 0.36 is 0.6634187417298207\n",
      "F1 score at threshold 0.37 is 0.6640416767627817\n",
      "F1 score at threshold 0.38 is 0.6630434782608695\n",
      "F1 score at threshold 0.39 is 0.6623616236162361\n",
      "F1 score at threshold 0.4 is 0.6615489382777193\n",
      "F1 score at threshold 0.41 is 0.6614722932119929\n",
      "F1 score at threshold 0.42 is 0.6610552763819095\n",
      "F1 score at threshold 0.43 is 0.6605039888565278\n",
      "F1 score at threshold 0.44 is 0.6598201186451489\n",
      "F1 score at threshold 0.45 is 0.6583922829581994\n",
      "F1 score at threshold 0.46 is 0.6575769380599922\n",
      "F1 score at threshold 0.47 is 0.6556819667843599\n",
      "F1 score at threshold 0.48 is 0.6534105873057676\n",
      "F1 score at threshold 0.49 is 0.6514437437769666\n",
      "F1 score at threshold 0.5 is 0.6506523921043827\n"
     ]
    }
   ],
   "source": [
    "pred_google_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_google_val_y>thresh).astype(int))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375806/375806 [==============================] - 19s 50us/sample\n"
     ]
    }
   ],
   "source": [
    "pred_google_test_y = model.predict([test_X], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "del word_index, embeddings_index, embedding_matrix, model, inp, x\n",
    "import gc; gc.collect()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 100, 300)          15000000  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 100, 128)          140544    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 15,142,625\n",
      "Trainable params: 15,142,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_FILE = './data/glove.840B.300d/glove.840B.300d.txt'\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
    "\n",
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "inp = Input(shape=(maxlen,))\n",
    "x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(16, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1175509 samples, validate on 130613 samples\n",
      "Epoch 1/2\n",
      "1175509/1175509 [==============================] - 572s 486us/sample - loss: 0.1159 - acc: 0.9541 - val_loss: 0.1002 - val_acc: 0.9606\n",
      "Epoch 2/2\n",
      "1175509/1175509 [==============================] - 247s 210us/sample - loss: 0.0940 - acc: 0.9629 - val_loss: 0.0993 - val_acc: 0.9607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f06d4b30b00>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_y, batch_size=512, epochs=2, validation_data=(val_X, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130613/130613 [==============================] - 7s 51us/sample\n",
      "F1 score at threshold 0.1 is 0.5812281782706921\n",
      "F1 score at threshold 0.11 is 0.589227284168135\n",
      "F1 score at threshold 0.12 is 0.5961300243475289\n",
      "F1 score at threshold 0.13 is 0.6048050139275766\n",
      "F1 score at threshold 0.14 is 0.6118741692512184\n",
      "F1 score at threshold 0.15 is 0.6177807787530948\n",
      "F1 score at threshold 0.16 is 0.6231559716830327\n",
      "F1 score at threshold 0.17 is 0.6286720415160781\n",
      "F1 score at threshold 0.18 is 0.6341944574917803\n",
      "F1 score at threshold 0.19 is 0.6380420781451266\n",
      "F1 score at threshold 0.2 is 0.6423075061704496\n",
      "F1 score at threshold 0.21 is 0.6468799058084773\n",
      "F1 score at threshold 0.22 is 0.6502580389043271\n",
      "F1 score at threshold 0.23 is 0.6542328574301227\n",
      "F1 score at threshold 0.24 is 0.6560593737291582\n",
      "F1 score at threshold 0.25 is 0.65775126015842\n",
      "F1 score at threshold 0.26 is 0.6591215865434534\n",
      "F1 score at threshold 0.27 is 0.661800997637175\n",
      "F1 score at threshold 0.28 is 0.6631260289978226\n",
      "F1 score at threshold 0.29 is 0.6648062681120533\n",
      "F1 score at threshold 0.3 is 0.6662688510361289\n",
      "F1 score at threshold 0.31 is 0.6681646298021593\n",
      "F1 score at threshold 0.32 is 0.6707263064658991\n",
      "F1 score at threshold 0.33 is 0.6725208344985737\n",
      "F1 score at threshold 0.34 is 0.6727683615819209\n",
      "F1 score at threshold 0.35 is 0.6734414249828728\n",
      "F1 score at threshold 0.36 is 0.6736744830772785\n",
      "F1 score at threshold 0.37 is 0.6735932757413029\n",
      "F1 score at threshold 0.38 is 0.6729522687094874\n",
      "F1 score at threshold 0.39 is 0.6725737392959086\n",
      "F1 score at threshold 0.4 is 0.6717988813375835\n",
      "F1 score at threshold 0.41 is 0.6707931306511319\n",
      "F1 score at threshold 0.42 is 0.6695247427731504\n",
      "F1 score at threshold 0.43 is 0.668437306979617\n",
      "F1 score at threshold 0.44 is 0.6679543896816\n",
      "F1 score at threshold 0.45 is 0.6667085664006033\n",
      "F1 score at threshold 0.46 is 0.6658637083993661\n",
      "F1 score at threshold 0.47 is 0.6658990596814431\n",
      "F1 score at threshold 0.48 is 0.6649018595041322\n",
      "F1 score at threshold 0.49 is 0.6641032325338895\n",
      "F1 score at threshold 0.5 is 0.6624991774692373\n"
     ]
    }
   ],
   "source": [
    "pred_glove_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_glove_val_y>thresh).astype(int))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375806/375806 [==============================] - 20s 54us/sample\n"
     ]
    }
   ],
   "source": [
    "pred_glove_test_y = model.predict([test_X], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "del word_index, embeddings_index, all_embs, embedding_matrix, model, inp, x\n",
    "import gc \n",
    "gc.collect()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = './data/wiki-news-300d-1M/wiki-news-300d-1M.vec'\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE) if len(o)>100)\n",
    "\n",
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "inp = Input(shape=(maxlen,))\n",
    "x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(16, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1175509 samples, validate on 130613 samples\n",
      "Epoch 1/2\n",
      "1175509/1175509 [==============================] - 247s 210us/sample - loss: 0.1151 - acc: 0.9555 - val_loss: 0.1026 - val_acc: 0.9600\n",
      "Epoch 2/2\n",
      "1175509/1175509 [==============================] - 247s 210us/sample - loss: 0.0931 - acc: 0.9625 - val_loss: 0.1049 - val_acc: 0.9584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0833256ef0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_y, batch_size=512, epochs=2, validation_data=(val_X, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130613/130613 [==============================] - 7s 51us/sample\n",
      "F1 score at threshold 0.1 is 0.5341006125858548\n",
      "F1 score at threshold 0.11 is 0.5431394906879513\n",
      "F1 score at threshold 0.12 is 0.552614188532556\n",
      "F1 score at threshold 0.13 is 0.5617058449809402\n",
      "F1 score at threshold 0.14 is 0.5703520641737228\n",
      "F1 score at threshold 0.15 is 0.5762069533695832\n",
      "F1 score at threshold 0.16 is 0.5820526778610611\n",
      "F1 score at threshold 0.17 is 0.589202077833603\n",
      "F1 score at threshold 0.18 is 0.5952576339999136\n",
      "F1 score at threshold 0.19 is 0.6017706872370266\n",
      "F1 score at threshold 0.2 is 0.6065675892142032\n",
      "F1 score at threshold 0.21 is 0.6110685129222859\n",
      "F1 score at threshold 0.22 is 0.6157574649046595\n",
      "F1 score at threshold 0.23 is 0.6212935507783544\n",
      "F1 score at threshold 0.24 is 0.6251876876876877\n",
      "F1 score at threshold 0.25 is 0.6288184711862795\n",
      "F1 score at threshold 0.26 is 0.6325706594885598\n",
      "F1 score at threshold 0.27 is 0.6358814656221108\n",
      "F1 score at threshold 0.28 is 0.6391691686764778\n",
      "F1 score at threshold 0.29 is 0.6428286852589641\n",
      "F1 score at threshold 0.3 is 0.6452976400140895\n",
      "F1 score at threshold 0.31 is 0.6478687191993091\n",
      "F1 score at threshold 0.32 is 0.6508857509627727\n",
      "F1 score at threshold 0.33 is 0.6528749935189506\n",
      "F1 score at threshold 0.34 is 0.6551435156086319\n",
      "F1 score at threshold 0.35 is 0.6571111228645474\n",
      "F1 score at threshold 0.36 is 0.6575210846589089\n",
      "F1 score at threshold 0.37 is 0.65857997735727\n",
      "F1 score at threshold 0.38 is 0.6602480417754568\n",
      "F1 score at threshold 0.39 is 0.6611053180396247\n",
      "F1 score at threshold 0.4 is 0.6629760850310008\n",
      "F1 score at threshold 0.41 is 0.6652499720389218\n",
      "F1 score at threshold 0.42 is 0.666252611371464\n",
      "F1 score at threshold 0.43 is 0.6679204422408389\n",
      "F1 score at threshold 0.44 is 0.6688524590163936\n",
      "F1 score at threshold 0.45 is 0.669070186660464\n",
      "F1 score at threshold 0.46 is 0.6688193506722245\n",
      "F1 score at threshold 0.47 is 0.6699075171923168\n",
      "F1 score at threshold 0.48 is 0.6689799581214478\n",
      "F1 score at threshold 0.49 is 0.6700862953352241\n",
      "F1 score at threshold 0.5 is 0.6689415635854\n"
     ]
    }
   ],
   "source": [
    "pred_fasttext_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_fasttext_val_y>thresh).astype(int))))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375806/375806 [==============================] - 19s 50us/sample\n"
     ]
    }
   ],
   "source": [
    "pred_fasttext_test_y = model.predict([test_X], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "del word_index, embeddings_index, all_embs, embedding_matrix, model, inp, x\n",
    "import gc \n",
    "gc.collect()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = './data/paragram_300_sl999/paragram_300_sl999.txt'\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE, encoding=\"utf8\", errors='ignore') if len(o)>100)\n",
    "\n",
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "inp = Input(shape=(maxlen,))\n",
    "x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(16, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1175509 samples, validate on 130613 samples\n",
      "Epoch 1/2\n",
      "1175509/1175509 [==============================] - 246s 209us/sample - loss: 0.1154 - acc: 0.9551 - val_loss: 0.1025 - val_acc: 0.9592\n",
      "Epoch 2/2\n",
      "1175509/1175509 [==============================] - 246s 209us/sample - loss: 0.0951 - acc: 0.9625 - val_loss: 0.0995 - val_acc: 0.9608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f08a8f09080>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_y, batch_size=512, epochs=2, validation_data=(val_X, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130613/130613 [==============================] - 7s 52us/sample\n",
      "F1 score at threshold 0.1 is 0.600457113286472\n",
      "F1 score at threshold 0.11 is 0.6073206184204731\n",
      "F1 score at threshold 0.12 is 0.6140485083022095\n",
      "F1 score at threshold 0.13 is 0.6207275726198112\n",
      "F1 score at threshold 0.14 is 0.6265262373007735\n",
      "F1 score at threshold 0.15 is 0.6333838575217885\n",
      "F1 score at threshold 0.16 is 0.6389637904468414\n",
      "F1 score at threshold 0.17 is 0.6421571017602028\n",
      "F1 score at threshold 0.18 is 0.6474777448071216\n",
      "F1 score at threshold 0.19 is 0.6496917447746979\n",
      "F1 score at threshold 0.2 is 0.6531005785040088\n",
      "F1 score at threshold 0.21 is 0.6547490625160528\n",
      "F1 score at threshold 0.22 is 0.6580658586068772\n",
      "F1 score at threshold 0.23 is 0.6606277649041501\n",
      "F1 score at threshold 0.24 is 0.66322402044293\n",
      "F1 score at threshold 0.25 is 0.6663438777706048\n",
      "F1 score at threshold 0.26 is 0.6682990532158015\n",
      "F1 score at threshold 0.27 is 0.6705895292564893\n",
      "F1 score at threshold 0.28 is 0.6712207042097078\n",
      "F1 score at threshold 0.29 is 0.6718241955376164\n",
      "F1 score at threshold 0.3 is 0.6730475165656681\n",
      "F1 score at threshold 0.31 is 0.6745115960242202\n",
      "F1 score at threshold 0.32 is 0.6751959428307975\n",
      "F1 score at threshold 0.33 is 0.6755829505146247\n",
      "F1 score at threshold 0.34 is 0.6755393996247655\n",
      "F1 score at threshold 0.35 is 0.6751419110690634\n",
      "F1 score at threshold 0.36 is 0.6745752608047689\n",
      "F1 score at threshold 0.37 is 0.6746451768101996\n",
      "F1 score at threshold 0.38 is 0.6751939864209506\n",
      "F1 score at threshold 0.39 is 0.6750900323506074\n",
      "F1 score at threshold 0.4 is 0.6744543498309253\n",
      "F1 score at threshold 0.41 is 0.6723689103756043\n",
      "F1 score at threshold 0.42 is 0.672543135783946\n",
      "F1 score at threshold 0.43 is 0.6708661417322835\n",
      "F1 score at threshold 0.44 is 0.6700088843761898\n",
      "F1 score at threshold 0.45 is 0.6692666709289686\n",
      "F1 score at threshold 0.46 is 0.6662799690641917\n",
      "F1 score at threshold 0.47 is 0.6653246753246753\n",
      "F1 score at threshold 0.48 is 0.6649646504320502\n",
      "F1 score at threshold 0.49 is 0.6615557464807349\n",
      "F1 score at threshold 0.5 is 0.6583527842614204\n"
     ]
    }
   ],
   "source": [
    "pred_paragram_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_paragram_val_y>thresh).astype(int))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375806/375806 [==============================] - 19s 50us/sample\n"
     ]
    }
   ],
   "source": [
    "pred_paragram_test_y = model.predict([test_X], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "del word_index, embeddings_index, all_embs, embedding_matrix, model, inp, x\n",
    "import gc\n",
    "gc.collect()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score at threshold 0.1 is 0.5784472957609226\n",
      "F1 score at threshold 0.11 is 0.5878493418047424\n",
      "F1 score at threshold 0.12 is 0.5965923539883021\n",
      "F1 score at threshold 0.13 is 0.6044098573281452\n",
      "F1 score at threshold 0.14 is 0.6114879746277861\n",
      "F1 score at threshold 0.15 is 0.6183106804826627\n",
      "F1 score at threshold 0.16 is 0.6243840116809636\n",
      "F1 score at threshold 0.17 is 0.6295182116906558\n",
      "F1 score at threshold 0.18 is 0.6361368663811361\n",
      "F1 score at threshold 0.19 is 0.640974212034384\n",
      "F1 score at threshold 0.2 is 0.6450768410335967\n",
      "F1 score at threshold 0.21 is 0.648640690941211\n",
      "F1 score at threshold 0.22 is 0.6521587916728772\n",
      "F1 score at threshold 0.23 is 0.6551915043535155\n",
      "F1 score at threshold 0.24 is 0.6587851610273135\n",
      "F1 score at threshold 0.25 is 0.6623390005151983\n",
      "F1 score at threshold 0.26 is 0.6647552520460825\n",
      "F1 score at threshold 0.27 is 0.6676157334176948\n",
      "F1 score at threshold 0.28 is 0.6696842217370467\n",
      "F1 score at threshold 0.29 is 0.6724547023295945\n",
      "F1 score at threshold 0.3 is 0.674550408719346\n",
      "F1 score at threshold 0.31 is 0.6748885096074436\n",
      "F1 score at threshold 0.32 is 0.6762132947010643\n",
      "F1 score at threshold 0.33 is 0.6788649926810044\n",
      "F1 score at threshold 0.34 is 0.6793397837222537\n",
      "F1 score at threshold 0.35 is 0.6805141152168924\n",
      "F1 score at threshold 0.36 is 0.680969178280229\n",
      "F1 score at threshold 0.37 is 0.6815740308267164\n",
      "F1 score at threshold 0.38 is 0.6810995752713545\n",
      "F1 score at threshold 0.39 is 0.6820347867524422\n",
      "F1 score at threshold 0.4 is 0.6820586820586821\n",
      "F1 score at threshold 0.41 is 0.6813853338994359\n",
      "F1 score at threshold 0.42 is 0.680864084205373\n",
      "F1 score at threshold 0.43 is 0.6795576697349724\n",
      "F1 score at threshold 0.44 is 0.6792288013976414\n",
      "F1 score at threshold 0.45 is 0.6782050475171503\n",
      "F1 score at threshold 0.46 is 0.677175363884828\n",
      "F1 score at threshold 0.47 is 0.6755111196564763\n",
      "F1 score at threshold 0.48 is 0.6732622049789848\n",
      "F1 score at threshold 0.49 is 0.6698876991381563\n",
      "F1 score at threshold 0.5 is 0.6673691142574909\n"
     ]
    }
   ],
   "source": [
    "pred_val_y = 0.25*pred_glove_val_y + 0.25*pred_fasttext_val_y + 0.25*pred_paragram_val_y + 0.25*pred_google_val_y\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_val_y>thresh).astype(int))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_y = 0.25*pred_glove_test_y + 0.25*pred_fasttext_test_y + 0.25*pred_paragram_test_y + 0.25*pred_google_test_y\n",
    "pred_test_y = (pred_test_y>0.34).astype(int)\n",
    "out_df = pd.DataFrame({\"qid\":test_df[\"qid\"].values})\n",
    "out_df['prediction'] = pred_test_y\n",
    "out_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
